# Week 4

# 1 Word Embeddings

## 1.1 Basic Word Representations

### 1.1.1 One-hot vectors

- Pro
  - Simple
  - No implied ordering
- Con
  - Huge vectors
  - No embedded meaning

<p align="center">
  <img src="../res/img/img80.png" width="500"/>
  <img src="../res/img/img81.png" width="500"/>
</p>

### 1.1.2 Word embeddings

- Pro
  - Low dimension
  - embed meaning

<p align="center">
  <img src="../res/img/img82.png" width="500"/>
  <img src="../res/img/img83.png" width="500"/>
</p>

## 1.2 Process

<p align="center">
  <img src="../res/img/img84.png" width="600"/>
</p>

## 1.3 Methods

- Basic methods

<p align="center">
  <img src="../res/img/img85.png" width="600"/>
</p>

- Advanced methods

<p align="center">
  <img src="../res/img/img86.png" width="600"/>
</p>

# 2 Continuous Bag-of-Words Model

## 2.1 Introduction

- Predict the center word

<p align="center">
  <img src="../res/img/img87.png" width="500"/>
  <img src="../res/img/img88.png" width="500"/>
</p>

## 2.2 Implementation
